[paper link](https://arxiv.org/pdf/2404.03118)

## Interpretability Functions

### Layer Attentions
![[Pasted image 20251202133739.png]]

![[notes_mine.jpg]]

### Relevancy Map

![[Pasted image 20251202133802.png]]
Example: 
![[Pasted image 20251202133726.png]]


### Causal Interpretation



## Important Referencess
![[Pasted image 20251202134212.png]]

![[Pasted image 20251202134227.png]]



## Code repo
https://github.com/IntelLabs/lvlm-interpret

#### plan
to create similar tool but for OCR visulaization, only two parts will be implemented, the layer-attentions and relelvancy map
Causal Interpretation and CLEANN method is not understood that well. 
![[Pasted image 20251202135145.png]]

![[Pasted image 20251202135157.png]]
![[Pasted image 20251202135246.png]]

