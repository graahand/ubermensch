{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4692d1-9e26-4c50-8e62-ac45e49bcd87",
   "metadata": {},
   "source": [
    "# Molmo and PixMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608dc47f-b0d9-4dd7-8e75-fd00dd844765",
   "metadata": {},
   "source": [
    "### Testing out the 1B parameter model locally, let's see if it fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c290b6-8bba-4ccc-af47-f613050e3627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: torchvision in /home/graahand/miniconda3/lib/python3.13/site-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: numpy in /home/graahand/miniconda3/lib/python3.13/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: torch==2.8.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torchvision) (2.8.0+cu126)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch==2.8.0->torchvision) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from jinja2->torch==2.8.0->torchvision) (3.0.2)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install einops torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336d14fc-afc9-473c-a60c-21b985f9a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in /home/graahand/miniconda3/lib/python3.13/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/graahand/miniconda3/lib/python3.13/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/graahand/miniconda3/lib/python3.13/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /home/graahand/miniconda3/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/graahand/miniconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Installing collected packages: safetensors, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5/5\u001b[0m [transformers]0m \u001b[32m4/5\u001b[0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.1.10 huggingface-hub-0.35.1 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.56.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f34af4-8cf0-404f-80ff-37e12e7960f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/graahand/miniconda3/lib/python3.13/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /home/graahand/miniconda3/lib/python3.13/site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/graahand/miniconda3/lib/python3.13/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from tensorflow) (2.1.2)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /home/graahand/miniconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/graahand/miniconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m620.8/620.8 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.75.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (414 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, markdown, h5py, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21/21\u001b[0m [tensorflow]0m \u001b[32m20/21\u001b[0m [tensorflow]]e_pasta]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.0 h5py-3.14.0 keras-3.11.3 libclang-18.1.1 markdown-3.9 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.32.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0fe7a3f-4b03-4c9a-b414-7fbfdeb6cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/graahand/miniconda3/lib/python3.13/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /home/graahand/miniconda3/lib/python3.13/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/graahand/miniconda3/lib/python3.13/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from accelerate) (2.8.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from accelerate) (0.35.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/graahand/miniconda3/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/graahand/miniconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3cc19d-d511-4751-8df0-5c2ff5848522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graahand/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-23 23:44:32.239601: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig, GPT2TokenizerFast\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab8b33a-5140-42cc-9cbf-fa776d07f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPTNeoXTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoProcessor\n",
    "\n",
    "# Load tokenizer explicitly to ensure correct class\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'allenai/MolmoE-1B-0924',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Then load processor (may still give warning, but you can override tokenizer after)\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/MolmoE-1B-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Override the tokenizer inside processor if needed\n",
    "processor.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5fc7bd-1279-458c-aa3e-35dcb986547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/MolmoE-1B-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b733e-78ad-4c71-b728-3d92bfbbf6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor.process(\n",
    "    images=[Image.open(requests.get(\"https://www.google.com/url?sa=i&url=https%3A%2F%2Fetc.usf.edu%2Fclipart%2F33800%2F33819%2Fnclock-03-45_33819.htm&psig=AOvVaw3rwYQNEk9SDIWR0P4d-NGq&ust=1758735626459000&source=images&cd=vfe&opi=89978449&ved=0CBUQjRxqFwoTCOCT0PW2748DFQAAAAAdAAAAABAE\", stream=True).raw)],\n",
    "    text=\"what time is it?\"\n",
    ")\n",
    "\n",
    "# move inputs to the correct device and make a batch of size 1\n",
    "inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "# generate output; maximum 200 new tokens; stop generation when <|endoftext|> is generated\n",
    "output = model.generate_from_batch(\n",
    "    inputs,\n",
    "    GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "# only get generated tokens; decode them to text\n",
    "generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "# print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab63a6-3373-4da3-9a6b-87ab8b22e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "print(\"ğŸ“¥ STEP 1: Downloading and opening image...\")\n",
    "image_url = 'https://www.media4math.com/sites/default/files/345.png'\n",
    "# NOTE: This URL is a Google redirect â€” it won't work directly with requests.get().raw!\n",
    "# Let's fix it by using the actual image URL:\n",
    "# From the clipart page, the actual image URL is:\n",
    "actual_image_url = \"https://etc.usf.edu/clipart/33800/33819/nclock-03-45_33819_lg.gif\"\n",
    "\n",
    "print(f\"   â†’ Using actual image URL: {actual_image_url}\")\n",
    "image = Image.open(requests.get(actual_image_url, stream=True).raw)\n",
    "print(f\"   â†’ Image size: {image.size}, mode: {image.mode}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"\\nğŸ§  STEP 2: Processing image + text with processor...\")\n",
    "inputs = processor.process(\n",
    "    images=[image],\n",
    "    text=\"what time is it?\"\n",
    ")\n",
    "\n",
    "print(f\"   â†’ Processor returned keys: {list(inputs.keys())}\")\n",
    "for k, v in inputs.items():\n",
    "    print(f\"     {k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"\\nâ¡ï¸ STEP 3: Moving inputs to model device and adding batch dim...\")\n",
    "inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "print(\"   â†’ After batching and moving to device:\")\n",
    "for k, v in inputs.items():\n",
    "    print(f\"     {k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"\\nGenerationStrategy STEP 4: Generating output...\")\n",
    "print(\"   â†’ Generation config: max_new_tokens=200, stop_strings=''\")\n",
    "\n",
    "# Optional: Enable logging for generation (if model supports it)\n",
    "# Some models allow: `output_attentions=True`, `output_scores=True`, etc.\n",
    "output = model.generate_from_batch(\n",
    "    inputs,\n",
    "    GenerationConfig(max_new_tokens=200, stop_strings=\"\"),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "print(f\"   â†’ Generated output shape: {output.shape}\")\n",
    "print(f\"   â†’ Full output (token IDs): {output[0].tolist()}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"\\nâœ‚ï¸ STEP 5: Extracting only generated tokens (after input length)...\")\n",
    "input_length = inputs['input_ids'].size(1)\n",
    "generated_tokens = output[0, input_length:]\n",
    "\n",
    "print(f\"   â†’ Input length: {input_length} tokens\")\n",
    "print(f\"   â†’ Generated tokens (IDs): {generated_tokens.tolist()}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"\\nğŸ”¤ STEP 6: Decoding generated tokens to text...\")\n",
    "generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(f\"   â†’ Decoded text: \\\"{generated_text}\\\"\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(\"\\nğŸ‰ FINAL OUTPUT:\")\n",
    "print(\"========================================\")\n",
    "print(generated_text)\n",
    "print(\"========================================\")\n",
    "print(\"\\nğŸ” DEBUG: Input tokens (before generation):\")\n",
    "input_ids = inputs['input_ids'][0]  # remove batch dim\n",
    "decoded_input = processor.tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "print(f\"   â†’ Token IDs: {input_ids.tolist()}\")\n",
    "print(f\"   â†’ Decoded input: \\\"{decoded_input}\\\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
